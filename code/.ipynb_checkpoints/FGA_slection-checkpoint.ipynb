{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8677fd85-cb52-440e-ab8f-051c5f8ee9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "import sklearn.metrics\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e311ba54-a757-4d7d-b071-f0a3af300687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Gemini API\n",
    "genai.configure(api_key=\"AIzaSyAdehFdko2Z3NMyDE_I0oUYtSTGJJgDitA\")  # Replace with your actual API Key\n",
    "\n",
    "# Function to generate adversarial samples using AI\n",
    "def generate_adv_snippet(message):\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")  \n",
    "    response = model.generate_content(message)\n",
    "    return response.text.strip() if response and hasattr(response, 'text') else \"No response generated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d63d6b9-3f37-4974-855a-15e1156ecb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_init(K, min_distance):\n",
    "    random_center = []\n",
    "    attempts = 0\n",
    "\n",
    "    while len(random_center) < K:\n",
    "        num = random.uniform(0, 1)\n",
    "        if all(abs(num - existing) >= min_distance for existing in random_center):\n",
    "            random_center.append(num)\n",
    "        attempts += 1\n",
    "        if attempts > 100:\n",
    "            raise ValueError(\"Failed to generate numbers with the required minimum distance. Try a different min_distance.\")\n",
    "\n",
    "    return np.array(random_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c5d87b-90d0-4ee0-a3c8-646b736103f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitness_score(pre_result_path, adv_file_path, snippet_len, penalty):\n",
    "    \"\"\"\n",
    "    Calculates the fitness score of adversarial files.\n",
    "    \"\"\"\n",
    "    with open(pre_result_path, 'r') as f:\n",
    "        pre_dic = {int(line.split('\\t')[0]): int(line.split('\\t')[1].strip()) for line in f}\n",
    "\n",
    "    with open(adv_file_path, 'r') as f:\n",
    "        test_data_dic = {json.loads(line)['idx']: json.loads(line)['target'] for line in f}\n",
    "\n",
    "    pre_list = [pre_dic[i] for i in test_data_dic.keys()]\n",
    "    true_list = [test_data_dic[i] for i in test_data_dic.keys()]\n",
    "\n",
    "    return 1 - sklearn.metrics.accuracy_score(true_list, pre_list) - penalty * snippet_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "377f64cb-5b33-42a0-bc4a-94ef1c2b54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(data, centroid_array):\n",
    "    cluster_num = len(centroid_array)\n",
    "    weights = []\n",
    "\n",
    "    for j in range(cluster_num):\n",
    "        weights_array = np.array([((data - centroid_array[j]) / (data - center)) ** 2 for center in centroid_array])\n",
    "        weights.append(1 / np.sum(weights_array))\n",
    "\n",
    "    return np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab382e7-c8fa-4ef7-b716-28527e1abeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(weight, data, centroid_array, alpha):\n",
    "    pal_weight = weight ** alpha\n",
    "    dis = np.array([np.abs(data - center) for center in centroid_array])\n",
    "    return np.dot(pal_weight, dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51fdc520-9944-4923-9d3c-87bebc42e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(pop_dict, centroid, centroid_array, decay_rate):\n",
    "    fitness_values = list(pop_dict.values())\n",
    "    keys_list = list(pop_dict.keys())\n",
    "\n",
    "    sorted_values = sorted(fitness_values, reverse=True)\n",
    "    factors = [math.exp(((1 / np.sum([(value - centroid) / (value - center) for center in centroid_array])) ** decay_rate) * abs(value - centroid)) for value in sorted_values]\n",
    "\n",
    "    p = np.array(factors) / np.sum(factors)\n",
    "    candidate = np.random.choice(sorted_values, p=p.ravel())\n",
    "    return keys_list[fitness_values.index(candidate)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9aec4c4-9cb0-487c-a71f-5dc16e3b4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_global_pop(offsprings, total_pop, fit_scores):\n",
    "    for offspring, fit_score in zip(offsprings, fit_scores):\n",
    "        total_pop[offspring] = fit_score\n",
    "\n",
    "    sorted_pop = dict(sorted(total_pop.items(), key=lambda x: x[1], reverse=True))\n",
    "    return {k: v for k, v in sorted_pop.items()[:len(total_pop)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceaf1c6f-8734-4fea-9421-6d7e0238073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vul_idx(label_list, pred, target):\n",
    "    return [i for i in label_list if pred[i] == 1 and target[i] == 1]\n",
    "\n",
    "def get_vul_codes(test_dicts, vul_idx):\n",
    "    return {i['idx']: i['func'] for i in test_dicts if i['idx'] in vul_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4ce2d3-a425-4aa6-ae38-14efd01e311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_adv_code_snippet(adv_snippet_file_path):\n",
    "    with open(adv_snippet_file_path, 'r') as f:\n",
    "        return [\" \".join(line.split()[::3]) for i, line in enumerate(f) if i >= 1 and line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a8ba38-dcec-4ada-8bb7-ea72775d49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_adver_sample_2_ast(vul_codes, insert_position, ad_content):\n",
    "    temp, names = [], []\n",
    "\n",
    "    for item in tqdm(vul_codes.keys()):\n",
    "        codes = vul_codes[item].split()\n",
    "        insert_idx = min(insert_position, len(codes))  # Prevents out-of-bounds errors\n",
    "\n",
    "        for adv in ad_content:\n",
    "            codes.insert(insert_idx, adv)\n",
    "            insert_idx += 1  # Increment for consecutive inserts\n",
    "\n",
    "        temp.append(\" \".join(codes))\n",
    "        names.append(item)\n",
    "\n",
    "    return temp, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7acfcac2-ee96-4d54-85b4-23cf03886ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_adv_to_json(ast_test_codes, ast_test_names, ast_test_labels, output_name):\n",
    "    ast_dicts = [{\"func\": code, \"idx\": i, \"project\": name, \"target\": label} for i, (code, name, label) in enumerate(zip(ast_test_codes, ast_test_names, ast_test_labels))]\n",
    "\n",
    "    with open(output_name, 'w') as f:\n",
    "        for data in ast_dicts:\n",
    "            f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fad617d-ebef-4f22-ad91-5c2fc32f080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated predictions.txt with 10 predictions.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_predictions(file_path, num_samples=10):\n",
    "    \"\"\"\n",
    "    Generates a dummy predictions.txt file with random predictions.\n",
    "\n",
    "    Format: <index> <predicted_label>\n",
    "    Example:\n",
    "    1    0\n",
    "    2    1\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for i in range(1, num_samples + 1):\n",
    "            prediction = random.choice([0, 1])  # Simulating binary classification (0 or 1)\n",
    "            f.write(f\"{i}\\t{prediction}\\n\")\n",
    "    \n",
    "    print(f\"âœ… Generated {file_path} with {num_samples} predictions.\")\n",
    "\n",
    "# ðŸ”¹ Create predictions.txt before calling get_fitness_score\n",
    "pre_result_path = \"predictions.txt\"\n",
    "generate_predictions(pre_result_path)  # This creates the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd5f143-a544-493f-828a-34b2da75e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated adv_samples.json with 10 adversarial samples.\n"
     ]
    }
   ],
   "source": [
    "def generate_adversarial_samples(file_path, num_samples=10):\n",
    "    \"\"\"\n",
    "    Generates a dummy adv_samples.json file with sample adversarial data.\n",
    "\n",
    "    Format (each line is a JSON object):\n",
    "    {\"idx\": <index>, \"target\": <actual_label>}\n",
    "    \"\"\"\n",
    "    adv_data = [{\"idx\": i, \"target\": random.choice([0, 1])} for i in range(1, num_samples + 1)]\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for data in adv_data:\n",
    "            f.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "    print(f\"âœ… Generated {file_path} with {num_samples} adversarial samples.\")\n",
    "\n",
    "# ðŸ”¹ Create adv_samples.json before calling get_fitness_score\n",
    "adv_file_path = \"adv_samples.json\"\n",
    "generate_adversarial_samples(adv_file_path)  # This creates the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "540711ae-eaf0-46e7-bcf7-c53f8aad4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitness Score: 0.19999999999999996\n",
      "\n",
      "ðŸ”¹ AI-Generated Adversarial Snippet:\n",
      "```python\n",
      "import hashlib\n",
      "import secrets\n",
      "import bcrypt\n",
      "\n",
      "def secure_login(username, password, users):\n",
      "    \"\"\"\n",
      "    Securely verifies user credentials against a stored user database.\n",
      "\n",
      "    Args:\n",
      "        username: The username entered by the user.\n",
      "        password: The password entered by the user.\n",
      "        users: A dictionary where keys are usernames and values are \n",
      "               dictionaries containing user information, including \n",
      "               \"salt\" and \"hashed_password\".\n",
      "\n",
      "    Returns:\n",
      "        True if the username and password match a user in the database, \n",
      "        False otherwise.\n",
      "    \"\"\"\n",
      "    if username not in users:\n",
      "        return False  # Avoid timing attacks\n",
      "\n",
      "    user_data = users[username]\n",
      "    stored_salt = user_data[\"salt\"]\n",
      "    stored_hash = user_data[\"hashed_password\"]\n",
      "\n",
      "    # Use bcrypt for password hashing and comparison\n",
      "    password_bytes = password.encode('utf-8') # Ensure bytes for bcrypt\n",
      "    salt_bytes = bytes.fromhex(stored_salt) # Convert hex string back to bytes\n",
      "    hashed_password = bcrypt.hashpw(password_bytes, salt_bytes)\n",
      "\n",
      "    return hashed_password == stored_hash\n",
      "\n",
      "\n",
      "def generate_salt():\n",
      "    \"\"\"Generates a cryptographically secure random salt.\"\"\"\n",
      "    return secrets.token_hex(16)  # Generate a 32-character hexadecimal string\n",
      "\n",
      "\n",
      "def hash_password(password, salt):\n",
      "    \"\"\"Hashes a password using bcrypt with the provided salt.\"\"\"\n",
      "    password_bytes = password.encode('utf-8')\n",
      "    salt_bytes = bytes.fromhex(salt)\n",
      "    hashed_password = bcrypt.hashpw(password_bytes, bcrypt.gensalt())  # generate new salt or use existing one\n",
      "    return hashed_password.decode('utf-8')\n",
      "\n",
      "\n",
      "\n",
      "# Example usage (in a real application, store user data securely, e.g., in a database)\n",
      "\n",
      "# This users database should be in a secure location NOT hardcoded like this\n",
      "users = {\n",
      "    \"bob\": {\"salt\": generate_salt(), \"hashed_password\": None},  # Initialize salt\n",
      "    \"alice\": {\"salt\": generate_salt(), \"hashed_password\": None}\n",
      "}\n",
      "\n",
      "\n",
      "# Hash passwords upon registration or initial setup\n",
      "for username, user_data in users.items():\n",
      "    password = input(f\"Enter password for {username}: \") # In a real application, get the password securely.\n",
      "    users[username][\"hashed_password\"] = hash_password(password, user_data[\"salt\"])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Login attempt\n",
      "username = input(\"Username: \")\n",
      "password = input(\"Password: \")\n",
      "\n",
      "\n",
      "if secure_login(username, password, users):\n",
      "    print(\"Login successful!\")\n",
      "else:\n",
      "    print(\"Login failed.\")\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "Key Security Improvements:\n",
      "\n",
      "* **Bcrypt:**  Uses bcrypt, a robust and widely recommended password hashing algorithm that is resistant to rainbow table attacks and brute-force attacks.  It also incorporates salting automatically.\n",
      "* **Salting:**  Each password is hashed with a unique, randomly generated salt.  This prevents identical passwords from having the same hash, further protecting against rainbow table attacks.  The salt is now stored as a hexadecimal string for easier database storage.\n",
      "* **Constant-Time Comparison:**  Instead of directly comparing the hashed password to the stored hash, the `bcrypt.checkpw()` function is used (within the `bcrypt.hashpw()` call effectively when comparing), or a similar constant-time comparison method. This helps prevent timing attacks, where an attacker might try to infer information about the password by measuring how long it takes to compare the hashes.\n",
      "* **Secure Salt Generation:**  Uses `secrets.token_hex()` to generate cryptographically secure random salts.\n",
      "* **UTF-8 Encoding:** Ensures passwords are encoded to UTF-8 bytes before hashing to handle a wider range of characters correctly and consistently.\n",
      "* **Avoids Early Exit:**  The function checks if the username exists in the `users` dictionary *before* performing any password hashing or comparison. This prevents timing attacks that could reveal whether a username exists in the database.\n",
      "* **No Hardcoded User Data:** The example code emphasizes that the user data should *not* be hardcoded but stored securely (e.g., in a database).\n",
      "\n",
      "\n",
      "\n",
      "Important:\n",
      "\n",
      "*  In a real-world application, **never store passwords in plain text**. Always hash and salt them.\n",
      "*  Store the user data (including the salt and hashed password) securely, ideally in a database with appropriate access controls.\n",
      "*  Consider using a more robust way to manage user sessions than simply printing \"Login successful!\" (e.g., session tokens, JWTs).\n",
      "*  Follow other security best practices, such as input validation, protection against SQL injection, and cross-site scripting (XSS) prevention.\n",
      "\n",
      "\n",
      "ðŸ“Œ Read Adversarial Code Snippets:\n",
      "1. {\"idx\": 0}\n",
      "2. {\"idx\": 1}\n",
      "3. {\"idx\": 1}\n",
      "4. {\"idx\": 1}\n",
      "5. {\"idx\": 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3880.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Modified Vulnerable Code Snippets:\n",
      "1. def vulnerable(): {\"idx\": 0} {\"idx\": 1} return False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict_items' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m offsprings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madv_snippet_3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madv_snippet_4\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     38\u001b[0m fit_scores \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.85\u001b[39m, \u001b[38;5;241m0.82\u001b[39m]\n\u001b[1;32m---> 39\u001b[0m updated_pop \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_global_pop\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffsprings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_pop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸš€ Updated Population:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(updated_pop)\n",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m, in \u001b[0;36mupdate_global_pop\u001b[1;34m(offsprings, total_pop, fit_scores)\u001b[0m\n\u001b[0;32m      3\u001b[0m     total_pop[offspring] \u001b[38;5;241m=\u001b[39m fit_score\n\u001b[0;32m      5\u001b[0m sorted_pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28msorted\u001b[39m(total_pop\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43msorted_pop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtotal_pop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_items' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example file paths (Modify as needed)\n",
    "    pre_result_path = \"predictions.txt\"\n",
    "    adv_file_path = \"adv_samples.json\"\n",
    "\n",
    "    snippet_len = 5  # Example length of snippets\n",
    "    penalty = 0.1  # Example penalty factor\n",
    "\n",
    "    # ðŸ”¹ Calculate Fitness Score\n",
    "    fitness_score = get_fitness_score(pre_result_path, adv_file_path, snippet_len, penalty)\n",
    "    print(f\"\\n Fitness Score: {fitness_score}\\n\")\n",
    "\n",
    "    # ðŸ”¹ Generate Adversarial Snippets (Using Gemini AI)\n",
    "    example_prompt = \"Write a secure login function in Python.\"\n",
    "    adv_snippet = generate_adv_snippet(example_prompt)\n",
    "    print(f\"ðŸ”¹ AI-Generated Adversarial Snippet:\\n{adv_snippet}\\n\")\n",
    "\n",
    "    # ðŸ”¹ Read and Process Adversarial Code Snippets\n",
    "    adv_snippets = read_adv_code_snippet(adv_file_path)\n",
    "    print(\"\\nðŸ“Œ Read Adversarial Code Snippets:\")\n",
    "    for idx, snippet in enumerate(adv_snippets[:5]):  # Print first 5\n",
    "        print(f\"{idx+1}. {snippet}\")\n",
    "\n",
    "    # ðŸ”¹ Process and Modify Vulnerable Code\n",
    "    test_data = [{\"idx\": 1, \"func\": \"def vulnerable(): return False\"}]\n",
    "    vul_idx = get_vul_idx([1], {1: 1}, {1: 1})\n",
    "    vul_codes = get_vul_codes(test_data, vul_idx)\n",
    "\n",
    "    # Insert adversarial samples\n",
    "    modified_codes, modified_names = add_adver_sample_2_ast(vul_codes, insert_position=2, ad_content=adv_snippets[:2])\n",
    "    print(\"\\nðŸ”¹ Modified Vulnerable Code Snippets:\")\n",
    "    for idx, mod_code in enumerate(modified_codes):\n",
    "        print(f\"{idx+1}. {mod_code}\")\n",
    "\n",
    "    # ðŸ”¹ Update Population\n",
    "    total_pop = {\"adv_snippet_1\": 0.8, \"adv_snippet_2\": 0.75}\n",
    "    offsprings = [\"adv_snippet_3\", \"adv_snippet_4\"]\n",
    "    fit_scores = [0.85, 0.82]\n",
    "    updated_pop = update_global_pop(offsprings, total_pop, fit_scores)\n",
    "    print(\"\\nðŸš€ Updated Population:\")\n",
    "    print(updated_pop)\n",
    "\n",
    "    # ðŸ”¹ Save Modified Data as JSON\n",
    "    write_adv_to_json(modified_codes, modified_names, [1]*len(modified_codes), \"modified_adv_data.json\")\n",
    "    print(\"\\nâœ… JSON file 'modified_adv_data.json' has been saved successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f40a56-a9f4-468b-ae98-9ce4af6f3b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
